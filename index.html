<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="DuoCLR: Dual-Surrogate Contrastive Learning for Skeleton-based Human Action Segmentation">
    <title>DuoCLR: Dual-Surrogate Contrastive Learning for Skeleton-based Human Action Segmentation</title>
    <link href="bootstrap.min.css" rel="stylesheet">
    <link href="style.css" rel="stylesheet">
</head>
<body>
    <div class="container">
        <div class="header text-center">
            <h2>DuoCLR: Dual-Surrogate Contrastive Learning for Skeleton-based Human Action Segmentation <br> (CVPR 2025)</h2>
            <h4>
                Haitao Tian<sup></sup>, Pierre Payeur<sup>1</sup>
            </h4>
            <h4><sup>University of Ottawa</h4>
        </div>

        <div class="row">
            <hr>
            <h2 class="text-center">Abstract</h2>
            <p>
                In this paper, a contrastive representation learning framework is proposed to enhance human action segmentation via pre-training using trimmed (single action) skeleton sequences. Unlike previous representation learning works that are tailored for action recognition and that build upon isolated sequence-wise representations, the proposed framework focuses on exploiting multi-scale representations in conjunction with cross-sequence variations. More specifically, it proposes a novel data augmentation strategy, “Shuffle and Warp”, which exploits diverse multi-action permutations. The latter effectively assists two surrogate tasks that are introduced in contrastive learning: Cross Permutation Contrasting (CPC) and Relative Order Reasoning (ROR). In optimization, CPC learns intra-class similarities by contrasting representations of the same action class across different permutations, while ROR reasons about inter-class contexts by predicting relative mapping between two permutations. Together, these tasks enable a Dual-Surrogate Contrastive Learning (DuoCLR) network to learn multi-scale feature representations optimized for action segmentation. In experiments, DuoCLR is pre-trained on a trimmed skeleton dataset and evaluated on an untrimmed dataset where it demonstrates a significant boost over state-the-art comparatives in both multi-class and multi-label action segmentation tasks. Lastly, ablation studies are conducted to evaluate the effectiveness of each component of the proposed approach.
            <p>
            <div class="text-center">
                <h3>
                    <a href="#" class="text-info">[Paper]</a>
                    <a href="#" class="text-info">[Code]</a>
                    <a href="#" class="text-info">[Appendix]</a>
                    <a href="#" class="text-info">[Poster]</a>
                </h3>
            </div>
        </div>
    </div>
</body>
</html>
